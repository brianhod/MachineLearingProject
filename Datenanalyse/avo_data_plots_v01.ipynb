{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4eae995-2831-43ce-99df-2fa81317e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020a9c42-7840-43bf-8b28-9a70f3b2a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Deine vorhandene Klasse für zeitbasierte Splits\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TimeBasedTrainTestSplit(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, year_column='year', test_year=None):\n",
    "        \"\"\"\n",
    "        Initialisiert den Splitter.\n",
    "        :param year_column: Name der Spalte, die das Jahr enthält\n",
    "        :param test_year: Das Jahr, das für die Tests verwendet wird\n",
    "        \"\"\"\n",
    "        self.year_column = year_column\n",
    "        self.test_year = test_year\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Diese Methode ist notwendig, um sich an die Scikit-Learn-Schnittstelle zu halten.\n",
    "        Hier ist kein Training nötig, daher wird nichts gemacht.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Führt den eigentlichen Split basierend auf dem Jahr durch.\n",
    "        :param X: Der DataFrame mit den Daten\n",
    "        :param y: Zielvariable, falls benötigt\n",
    "        :return: Train- und Test-Daten\n",
    "        \"\"\"\n",
    "        if self.test_year is None:\n",
    "            raise ValueError(\"Es muss ein Testjahr angegeben werden!\")\n",
    "\n",
    "        # Aufteilen der Daten in Trainings- und Testdatensätze\n",
    "        X_train = X[X[self.year_column] < self.test_year]\n",
    "        X_test = X[X[self.year_column] == self.test_year]\n",
    "\n",
    "        if y is not None:\n",
    "            y_train = y[X[self.year_column] < self.test_year]\n",
    "            y_test = y[X[self.year_column] == self.test_year]\n",
    "            return X_train, X_test, y_train, y_test\n",
    "        return X_train, X_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3652cc-029e-497e-823e-1f5d799c8fd8",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a7e4d9-c49a-4b3f-8ed3-acf8587e4c4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'avocado-updated-2020.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavocado-updated-2020.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m avocado_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the columns of the dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m avocado_data\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'avocado-updated-2020.csv'"
     ]
    }
   ],
   "source": [
    "# Laden des avocado CSV file\n",
    "file_path = 'avocado-updated-2020.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "avocado_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the columns of the dataset\n",
    "avocado_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd2b4e-bdfe-41c5-8fda-13a047ee7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung auf fehlende Werte (NaN)\n",
    "missing_values = avocado_data.isnull().sum()\n",
    "\n",
    "# Überblick über die Anzahl der fehlenden Werte pro Spalte\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cec8a3-5289-415a-9dfc-432b50d8d681",
   "metadata": {},
   "source": [
    "Ermilltung, wieviele Jahre an Daten wir zur verfügung haben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8460dfe-ee32-4767-997c-a0e3e20fcfc1",
   "metadata": {},
   "source": [
    "## Analyse der Zeitreihe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c80ac-8f46-4a8c-a1bd-19ad668ce121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schauen wir uns die eindeutigen Jahre im Datensatz an\n",
    "unique_years = avocado_data['year'].unique()\n",
    "unique_years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5065f8c-f070-447e-9c3b-0e74047883a8",
   "metadata": {},
   "source": [
    "Erkennnis: Zum Tranieren und Testen kann zwischen 2015-2019 und 2020 getrennt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087682ef-6c6a-437b-8642-03960be1a7e2",
   "metadata": {},
   "source": [
    "Die beiden Visualisierungen geben uns einige interessante Einblicke in die Avocado-Daten:\n",
    "\n",
    "**Durchschnittlicher Preis pro Jahr**: Der Preis der Avocados schwankte über die Jahre. Man kann beobachten, dass es in bestimmten Jahren Preisanstiege gab. Es wäre interessant, mögliche Ursachen für diese Schwankungen, wie saisonale Effekte oder Änderungen in der Nachfrage, zu untersuchen.\n",
    "\n",
    "**Gesamtes Verkaufsvolumen pro Jahr**: Hier siehst man, wie sich das Verkaufsvolumen über die Jahre verändert hat. Es gibt einige deutliche Veränderungen, wobei das Volumen in bestimmten Jahren höher ist. Dies könnte auf Marktdynamiken, Anbaubedingungen oder Verbraucherpräferenzen hinweisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1461f-38f7-49dd-9160-6390fc947a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Überblick über die durchschnittlichen Preise pro Jahr\n",
    "average_price_per_year = avocado_data.groupby('year')['average_price'].mean()\n",
    "\n",
    "# Überblick über das Verkaufsvolumen pro Jahr\n",
    "total_volume_per_year = avocado_data.groupby('year')['total_volume'].sum()\n",
    "\n",
    "# Visualisierung der durchschnittlichen Preise pro Jahr\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(average_price_per_year.index, average_price_per_year.values, marker='o')\n",
    "plt.title('Durchschnittlicher Avocado-Preis pro Jahr')\n",
    "plt.xlabel('Jahr')\n",
    "plt.ylabel('Durchschnittlicher Preis')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Visualisierung des gesamten Verkaufsvolumens pro Jahr\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(total_volume_per_year.index, total_volume_per_year.values, color='green')\n",
    "plt.title('Gesamtes Verkaufsvolumen von Avocados pro Jahr')\n",
    "plt.xlabel('Jahr')\n",
    "plt.ylabel('Verkaufsvolumen')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a18b3-954c-4ff7-9ff9-496a593b510a",
   "metadata": {},
   "source": [
    "## Analyse der Regionen\n",
    "\n",
    "**Gesamtes Verkaufsvolumen nach Region**: Das erste Diagramm zeigt, wie viel Avocados in den verschiedenen Regionen verkauft wurden. Regionen mit größerem Verkaufsvolumen sind weiter oben in der Liste.\n",
    "\n",
    "**Durchschnittlicher Preis nach Region**: Das zweite Diagramm zeigt die durchschnittlichen Preise pro Region. Du kannst erkennen, dass die Preise je nach Region unterschiedlich sind.\n",
    "\n",
    "Diese Visualisierungen bieten einen guten Überblick darüber, wo die meisten Avocados verkauft werden und wo sie teurer oder günstiger sind. Wenn du weitere Analysen benötigst oder andere Details untersuchen möchtest, lass es mich wissen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df0c0c7-4aae-47c2-98af-b3b97841cb18",
   "metadata": {},
   "source": [
    "Detailliertere Analyse der Avocado-Daten nach Regionen, unter Verwendung von Plotly für die Visualisierung. \n",
    "Verkaufsvolumen und die durchschnittlichen Preise von Avocados in verschiedenen Regionen der USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ade18-6b6f-4fa0-8a4c-a0f12733ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Gruppiere den avocado_data nach 'geography' und berechne den durchschnittlichen Preis und das gesamte Verkaufsvolumen\n",
    "avg_price_region = avocado_data.groupby('geography')['average_price'].mean()\n",
    "total_volume_region = avocado_data.groupby('geography')['total_volume'].sum()\n",
    "\n",
    "# Sortiere nach Verkaufsvolumen für bessere Darstellung\n",
    "total_volume_region_sorted = total_volume_region.sort_values(ascending=False)\n",
    "\n",
    "# Erstellen eines Balkendiagramms für das Verkaufsvolumen pro Region\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(total_volume_region_sorted.index, total_volume_region_sorted.values, color='skyblue')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Gesamtes Verkaufsvolumen von Avocados nach Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Verkaufsvolumen')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sortiere nach durchschnittlichem Preis für bessere Darstellung\n",
    "avg_price_region_sorted = avg_price_region.sort_values(ascending=False)\n",
    "\n",
    "# Erstellen eines Balkendiagramms für den durchschnittlichen Preis pro Region\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(avg_price_region_sorted.index, avg_price_region_sorted.values, color='lightgreen')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Durchschnittlicher Avocado-Preis nach Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Durchschnittlicher Preis (in USD)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08dc56-9039-4fdc-9abe-4a8d5a02e8e4",
   "metadata": {},
   "source": [
    "Es scheint, dass die Spalte \"geography\" in deem Datensatz  unterschiedliche Hierarchien von Regionen enthält, z.B. Staaten, regionale Märkte oder größere Gebiete (wie \"Total U.S.\"). Um dies zu überprüfen und zu analysieren, können wir die einzigartigen Werte der \"geography\"-Spalte genauer betrachten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd27a6e7-b61f-41fb-af84-6e7c0a8de2d9",
   "metadata": {},
   "source": [
    "Wir fügen eine neue Spalte namens \"geography_level\" hinzu, die die geografischen Ebenen wie folgt klassifiziert:\n",
    "\n",
    "Level 0: Für \"Total U.S.\" (gesamtnational).\n",
    "Level 1: Für größere Regionen oder Bundesstaaten (z.B. \"California\", \"Great Lakes\").\n",
    "Level 2: Für Städte oder Metropolregionen (z.B. \"Albany\", \"Chicago\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36185294-6764-4789-809d-b3a5d20bbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Definieren der Städte mit ihren Koordinaten\n",
    "static_coordinates = [\n",
    "    ('Albany', 42.6526, -73.7562),\n",
    "    ('Atlanta', 33.749, -84.388),\n",
    "    ('Baltimore/Washington', 39.2904, -76.6122),\n",
    "    ('Boise', 43.615, -116.2023),\n",
    "    ('Boston', 42.3601, -71.0589),\n",
    "    ('Buffalo/Rochester', 43.1566, -77.6088),\n",
    "    ('California', 36.7783, -119.4179),\n",
    "    ('Charlotte', 35.2271, -80.8431),\n",
    "    ('Chicago', 41.8781, -87.6298),\n",
    "    ('Cincinnati/Dayton', 39.1031, -84.512),\n",
    "    ('Columbus', 39.9612, -82.9988),\n",
    "    ('Dallas/Ft. Worth', 32.7767, -96.797),\n",
    "    ('Denver', 39.7392, -104.9903),\n",
    "    ('Detroit', 42.3314, -83.0458),\n",
    "    ('Grand Rapids', 42.9634, -85.6681),\n",
    "    ('Great Lakes', 45.0, -84.0),\n",
    "    ('Harrisburg/Scranton', 40.2732, -76.8867),\n",
    "    ('Hartford/Springfield', 41.7627, -72.6743),\n",
    "    ('Houston', 29.7604, -95.3698),\n",
    "    ('Indianapolis', 39.7684, -86.1581),\n",
    "    ('Jacksonville', 30.3322, -81.6557),\n",
    "    ('Las Vegas', 36.1699, -115.1398),\n",
    "    ('Los Angeles', 34.0522, -118.2437),\n",
    "    ('Louisville', 38.2527, -85.7585),\n",
    "    ('Miami/Ft. Lauderdale', 25.7617, -80.1918),\n",
    "    ('Midsouth', 35.1495, -90.0489),\n",
    "    ('Nashville', 36.1627, -86.7816),\n",
    "    ('New Orleans/Mobile', 29.9511, -90.0715),\n",
    "    ('New York', 40.7128, -74.006),\n",
    "    ('Northeast', 41.5, -75.0),\n",
    "    ('Northern New England', 44.0, -71.5),\n",
    "    ('Orlando', 28.5383, -81.3792),\n",
    "    ('Philadelphia', 39.9526, -75.1652),\n",
    "    ('Phoenix/Tucson', 33.4484, -112.074),\n",
    "    ('Pittsburgh', 40.4406, -79.9959),\n",
    "    ('Plains', 39.0119, -98.4842),\n",
    "    ('Portland', 45.5152, -122.6784),\n",
    "    ('Raleigh/Greensboro', 35.7796, -78.6382),\n",
    "    ('Richmond/Norfolk', 37.5407, -77.436),\n",
    "    ('Roanoke', 37.2709, -79.9414),\n",
    "    ('Sacramento', 38.5816, -121.4944),\n",
    "    ('San Diego', 32.7157, -117.1611),\n",
    "    ('San Francisco', 37.7749, -122.4194),\n",
    "    ('Seattle', 47.6062, -122.3321),\n",
    "    ('South Carolina', 33.8361, -81.1637),\n",
    "    ('South Central', 34.7465, -92.2896),\n",
    "    ('Southeast', 32.3182, -86.9023),\n",
    "    ('Spokane', 47.6588, -117.426),\n",
    "    ('St. Louis', 38.627, -90.1994),\n",
    "    ('Syracuse', 43.0481, -76.1474),\n",
    "    ('Tampa', 27.9506, -82.4572),\n",
    "    ('Total U.S.', 39.8283, -98.5795),\n",
    "    ('West', 39.1178, -120.013),\n",
    "    ('West Tex/New Mexico', 31.9686, -99.9018)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16db8357-cbe2-4859-80f5-1022de1181cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Funktion zur Klassifizierung der geographischen Ebenen\n",
    "def classify_geography(geo):\n",
    "    if geo == 'Total U.S.':\n",
    "        return '0'  # Gesamtnation\n",
    "    elif geo in ['California',\n",
    "                 'Great Lakes',\n",
    "                 'Midsouth',\n",
    "                 'Northeast',\n",
    "                 'Northern New England',\n",
    "                 'Plains',\n",
    "                 'South Carolina',\n",
    "                 'South Central',\n",
    "                 'Southeast',\n",
    "                 'West',\n",
    "                 'West Tex/New Mexico']:\n",
    "        return '1'  # Regionen oder Bundesstaaten\n",
    "    else:\n",
    "        return '2'  # Städte und Metropolregionen\n",
    "\n",
    "# Neue Spalte für geographische Ebenen basierend auf der Funktion hinzufügen\n",
    "avocado_data['geography_level'] = avocado_data['geography'].apply(classify_geography)\n",
    "\n",
    "# Erste Zeilen anzeigen, um das Ergebnis zu überprüfen\n",
    "avocado_data[['geography', 'geography_level']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4014fc-1188-46d6-9ee7-4cb2c8c27984",
   "metadata": {},
   "source": [
    "Hinzufügen eine Spalte 'latitude', 'longitude'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33fbb1-ca03-48e1-8e91-2676c3013eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Konvertiere die Koordinaten in ein DataFrame\n",
    "coordinates_df = pd.DataFrame(static_coordinates, columns=['geography', 'latitude', 'longitude'])\n",
    "\n",
    "# Mergen der avocado_data mit den Koordinaten basierend auf der Spalte 'geography'\n",
    "avocado_data = pd.merge(avocado_data, coordinates_df, how='left', on='geography')\n",
    "\n",
    "# Anzeigen der ersten Zeilen, um das Ergebnis zu überprüfen\n",
    "avocado_data[['geography', 'latitude', 'longitude']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414dd35b-51fb-4978-bb43-fb2106227ca2",
   "metadata": {},
   "source": [
    "Der DataFrame für die Level 1 Regionen mit den aggregierten Summen enthält die Spalten:\n",
    "\n",
    "geography: Name der Region.\n",
    "average_price: Durchschnittlicher Preis der Avocados.\n",
    "total_volume: Gesamtes Verkaufsvolumen in dieser Region.\n",
    "latitude und longitude: Koordinaten der Regionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ce946-be11-4a91-9e59-72236e3687a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Aggregieren der Level 1 Daten nach 'geography', sodass nur eine Zeile pro Region vorhanden ist\n",
    "level_1_aggregated = avocado_data[avocado_data['geography_level'] == '1'].groupby('geography').agg({\n",
    "    'average_price': 'mean',\n",
    "    'total_volume': 'sum',\n",
    "    'latitude': 'first',\n",
    "    'longitude': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "level_1_aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292a35a-f352-4540-8fec-665d16673b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Verwende die aggregierten Level-1-Daten für den Plot\n",
    "level_1_aggregated = level_1_aggregated.copy()\n",
    "\n",
    "# Erstellen der Textbeschreibung für jede Region in Level 1\n",
    "level_1_aggregated['text'] = (\n",
    "    level_1_aggregated['geography'] +\n",
    "    '<br>Durchschnittspreis: $' + level_1_aggregated['average_price'].round(2).astype(str) +\n",
    "    '<br>Verkaufsvolumen: ' + level_1_aggregated['total_volume'].astype(int).astype(str)\n",
    ")\n",
    "\n",
    "# Sicherstellen, dass Markergröße nicht zu klein ist (mindestens 10)\n",
    "marker_size = level_1_aggregated['total_volume'] / level_1_aggregated['total_volume'].max() * 50\n",
    "marker_size[marker_size < 10] = 10  # Set minimum size to 10\n",
    "\n",
    "# Erstellen der Plotly-Figur für Level 1\n",
    "fig_level_1 = go.Figure()\n",
    "\n",
    "# Füge die Marker hinzu\n",
    "fig_level_1.add_trace(go.Scattergeo(\n",
    "    locationmode='USA-states',\n",
    "    lon=level_1_aggregated['longitude'],\n",
    "    lat=level_1_aggregated['latitude'],\n",
    "    text=level_1_aggregated['text'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=marker_size,  # Größe relativ zum Volumen, Mindestgröße 10\n",
    "        opacity=0.7,\n",
    "        color=level_1_aggregated['average_price'],\n",
    "        colorscale='Viridis',\n",
    "        colorbar_title='Durchschnittspreis'\n",
    "    )\n",
    "))\n",
    "\n",
    "# Layout anpassen, einschließlich der Plot-Größe\n",
    "fig_level_1.update_layout(\n",
    "    title='Durchschnittspreis und Verkaufsvolumen von Avocados nach Level 1 Regionen',\n",
    "    geo=dict(\n",
    "        scope='usa',\n",
    "        projection_type='albers usa',\n",
    "        showland=True,\n",
    "        landcolor=\"rgb(250, 250, 250)\",\n",
    "        subunitcolor=\"rgb(217, 217, 217)\",\n",
    "        countrycolor=\"rgb(217, 217, 217)\",\n",
    "        countrywidth=0.5,\n",
    "        subunitwidth=0.5\n",
    "    ),\n",
    "    width=1200,  # Setze eine größere Breite\n",
    "    height=800   # Setze eine größere Höhe\n",
    ")\n",
    "\n",
    "# Plot anzeigen\n",
    "fig_level_1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26f0dc-8881-43ed-88a8-2df59fe6ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Aggregieren der Level 2 Daten nach 'geography', sodass nur eine Zeile pro Region vorhanden ist\n",
    "level_2_aggregated = avocado_data[avocado_data['geography_level'] == '2'].groupby('geography').agg({\n",
    "    'average_price': 'mean',\n",
    "    'total_volume': 'sum',\n",
    "    'latitude': 'first',\n",
    "    'longitude': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "level_2_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96abd3-455e-48ba-a59b-83aeae5a167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Verwende die aggregierten Level-1-Daten für den Plot\n",
    "level_2_aggregated = level_2_aggregated.copy()\n",
    "\n",
    "# Erstellen der Textbeschreibung für jede Region in Level 1\n",
    "level_2_aggregated['text'] = (\n",
    "    level_2_aggregated['geography'] +\n",
    "    '<br>Durchschnittspreis: $' + level_2_aggregated['average_price'].round(2).astype(str) +\n",
    "    '<br>Verkaufsvolumen: ' + level_2_aggregated['total_volume'].astype(int).astype(str)\n",
    ")\n",
    "\n",
    "# Sicherstellen, dass Markergröße nicht zu klein ist (mindestens 10)\n",
    "marker_size = level_2_aggregated['total_volume'] / level_2_aggregated['total_volume'].max() * 50\n",
    "marker_size[marker_size < 10] = 10  # Set minimum size to 10\n",
    "\n",
    "# Erstellen der Plotly-Figur für Level 1\n",
    "fig_level_2 = go.Figure()\n",
    "\n",
    "# Füge die Marker hinzu\n",
    "fig_level_2.add_trace(go.Scattergeo(\n",
    "    locationmode='USA-states',\n",
    "    lon=level_2_aggregated['longitude'],\n",
    "    lat=level_2_aggregated['latitude'],\n",
    "    text=level_2_aggregated['text'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=marker_size,  # Größe relativ zum Volumen, Mindestgröße 10\n",
    "        opacity=0.7,\n",
    "        color=level_1_aggregated['average_price'],\n",
    "        colorscale='Viridis',\n",
    "        colorbar_title='Durchschnittspreis'\n",
    "    )\n",
    "))\n",
    "\n",
    "# Layout anpassen, einschließlich der Plot-Größe\n",
    "fig_level_2.update_layout(\n",
    "    title='Durchschnittspreis und Verkaufsvolumen von Avocados nach Level 1 Regionen',\n",
    "    geo=dict(\n",
    "        scope='usa',\n",
    "        projection_type='albers usa',\n",
    "        showland=True,\n",
    "        landcolor=\"rgb(250, 250, 250)\",\n",
    "        subunitcolor=\"rgb(217, 217, 217)\",\n",
    "        countrycolor=\"rgb(217, 217, 217)\",\n",
    "        countrywidth=0.5,\n",
    "        subunitwidth=0.5\n",
    "    ),\n",
    "    width=1200,  # Setze eine größere Breite\n",
    "    height=800   # Setze eine größere Höhe\n",
    ")\n",
    "\n",
    "# Plot anzeigen\n",
    "fig_level_2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75c02f-394f-44dc-9d1b-83dab27cdfa1",
   "metadata": {},
   "source": [
    "## Korrelationen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e2f2c-d905-4639-b00e-8b75b4cf0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark Fischer\n",
    "\n",
    "# Konvertiere das Datum in ein datetime-Format und extrahiere Kalenderwoche und Jahr\n",
    "avocado_data['date'] = pd.to_datetime(avocado_data['date'])\n",
    "avocado_data['week'] = avocado_data['date'].dt.isocalendar().week\n",
    "avocado_data['year'] = avocado_data['date'].dt.year\n",
    "\n",
    "# Filter für San Francisco, organic small bags only (ohne large und xlarge bags), Jahr 2015\n",
    "sf_data_2015_only_small = avocado_data.loc[(avocado_data['geography'] == 'San Francisco') &\n",
    "                                           (avocado_data['type'] == 'organic') &\n",
    "                                           (avocado_data['small_bags'] > 0) &\n",
    "                                           (avocado_data['large_bags'] == 0) &\n",
    "                                           (avocado_data['xlarge_bags'] == 0) &\n",
    "                                           (avocado_data['year'] == 2015)].copy()\n",
    "\n",
    "# Konvertiere das Datum und extrahiere den Monat\n",
    "sf_data_2015_only_small['date'] = pd.to_datetime(sf_data_2015_only_small['date'])\n",
    "sf_data_2015_only_small['month'] = sf_data_2015_only_small['date'].dt.month\n",
    "\n",
    "# Berechne das durchschnittliche monatliche Volumen für Farbcodierung\n",
    "volume_colors_monthly = sf_data_2015_only_small.groupby('month')['total_volume'].mean()\n",
    "\n",
    "# Erstelle die Boxplot-Daten basierend auf monatlichen Durchschnittspreisen\n",
    "monthly_boxplot_data = [sf_data_2015_only_small[sf_data_2015_only_small['month'] == month]['average_price']\n",
    "                        for month in sf_data_2015_only_small['month'].unique()]\n",
    "\n",
    "# Erstelle den Plot mit sowohl horizontalem als auch vertikalem gestrichelten Grid\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "box = ax.boxplot(monthly_boxplot_data, patch_artist=True, showmeans=True)\n",
    "\n",
    "# Wende die Farbgebung basierend auf dem monatlichen Volumen an\n",
    "cmap = plt.cm.viridis\n",
    "for patch, volume in zip(box['boxes'], volume_colors_monthly):\n",
    "    color = cmap(volume / max(volume_colors_monthly))\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Füge eine Farbskala hinzu, um Volumen darzustellen\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=volume_colors_monthly.min(), vmax=volume_colors_monthly.max()))\n",
    "sm.set_array([])\n",
    "fig.colorbar(sm, ax=ax, label='Average Total Volume')\n",
    "\n",
    "# Setze Titel und Achsenbeschriftungen\n",
    "ax.set_title('Monthly Average Price for Organic Small Bags in San Francisco (2015) with Volume Colored Boxplots')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Average Price')\n",
    "ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "# Füge ein gestricheltes Grid sowohl horizontal als auch vertikal hinzu\n",
    "ax.grid(True, linestyle='--', which='both', color='grey', alpha=0.7)\n",
    "\n",
    "# Zeige den Plot an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b2c18a-95a7-443b-9c5c-35fe3bdf8170",
   "metadata": {},
   "source": [
    "Erkenntnis: Es gibt Abhängigkeiten zum Preis und der Jahreszeit\n",
    "Wir werden Jahreszeiten und Anbaugebiete/Entfrneungen zu Anbaugebiete berücksichtigen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529494e2-f841-4141-b2d7-59636b89557a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951b53a-b0a1-49d9-b289-33c2fae8be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Ensure the date column is datetime\n",
    "avocado_data['date'] = pd.to_datetime(avocado_data['date'])\n",
    "\n",
    "# Create the scatter plot separating by type\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot for 'conventional' avocados\n",
    "plt.scatter(avocado_data[avocado_data['type'] == 'conventional']['total_volume'],\n",
    "            avocado_data[avocado_data['type'] == 'conventional']['average_price'],\n",
    "            color='blue', label='Conventional')\n",
    "\n",
    "# Scatter plot for 'organic' avocados\n",
    "plt.scatter(avocado_data[avocado_data['type'] == 'organic']['total_volume'],\n",
    "            avocado_data[avocado_data['type'] == 'organic']['average_price'],\n",
    "            color='green', label='Organic')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Price vs Total Volume of Avocados (Separated by Type)', fontsize=14)\n",
    "plt.xlabel('Total Volume', fontsize=12)\n",
    "plt.ylabel('Average Price ($)', fontsize=12)\n",
    "\n",
    "# Adding legend to distinguish between 'conventional' and 'organic'\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca5cf0-4c68-4042-a553-ca89258f24c8",
   "metadata": {},
   "source": [
    "Erkenntnis: Bio und konventioenne Avocados unterscheiden sich schark zwischen Volumen und Preis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd83462-a62a-41c0-8e4f-50f3e5b5b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-adding the '1/total_volume' column for calculation\n",
    "avocado_data['1/total_volume'] = 1 / avocado_data['total_volume']\n",
    "\n",
    "# Creating two plots to separate 'conventional' and 'organic'\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot 1: Conventional Avocados\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(avocado_data[avocado_data['type'] == 'conventional']['average_price'],\n",
    "            avocado_data[avocado_data['type'] == 'conventional']['1/total_volume'],\n",
    "            color='blue', label='Conventional')\n",
    "plt.title('Conventional: Inverse Volume vs Price')\n",
    "plt.xlabel('Average Price ($)')\n",
    "plt.ylabel('1 / Total Volume')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: Organic Avocados\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(avocado_data[avocado_data['type'] == 'organic']['average_price'],\n",
    "            avocado_data[avocado_data['type'] == 'organic']['1/total_volume'],\n",
    "            color='green', label='Organic')\n",
    "plt.title('Organic: Inverse Volume vs Price')\n",
    "plt.xlabel('Average Price ($)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0635699e-30b0-4314-b73f-8209ed55ac33",
   "metadata": {},
   "source": [
    "Erkenntnis: Die Verteilung weist eine Normalverteilung auf (mit Ausreißern). Dieses ist für viele ML Algothmen von Vorteil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3caae0e-9326-43d2-8bfc-327acce500db",
   "metadata": {},
   "source": [
    "## Analyse von zwei Städten (Los Angeles and New York)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc549060-71b5-4f5d-981c-43bbda73445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for Los Angeles and New York\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Los Angeles Conventional\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(avocado_data[(avocado_data['geography'] == 'Los Angeles') & (avocado_data['type'] == 'conventional')]['average_price'],\n",
    "            avocado_data[(avocado_data['geography'] == 'Los Angeles') & (avocado_data['type'] == 'conventional')]['1/total_volume'],\n",
    "            color='blue', label='Los Angeles - Conventional')\n",
    "plt.title('Los Angeles Conventional: Inverse Volume vs Price')\n",
    "plt.xlabel('Average Price ($)')\n",
    "plt.ylabel('1 / Total Volume')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: Los Angeles Organic\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(avocado_data[(avocado_data['geography'] == 'Los Angeles') & (avocado_data['type'] == 'organic')]['average_price'],\n",
    "            avocado_data[(avocado_data['geography'] == 'Los Angeles') & (avocado_data['type'] == 'organic')]['1/total_volume'],\n",
    "            color='green', label='Los Angeles - Organic')\n",
    "plt.title('Los Angeles Organic: Inverse Volume vs Price')\n",
    "plt.xlabel('Average Price ($)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 3: New York Conventional\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(avocado_data[(avocado_data['geography'] == 'New York') & (avocado_data['type'] == 'conventional')]['average_price'],\n",
    "            avocado_data[(avocado_data['geography'] == 'New York') & (avocado_data['type'] == 'conventional')]['1/total_volume'],\n",
    "            color='blue', label='New York - Conventional')\n",
    "plt.title('New York Conventional: Inverse Volume vs Price')\n",
    "plt.xlabel('Average Price ($)')\n",
    "plt.ylabel('1 / Total Volume')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 4: New York Organic\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(avocado_data[(avocado_data['geography'] == 'New York') & (avocado_data['type'] == 'organic')]['average_price'],\n",
    "            avocado_data[(avocado_data['geography'] == 'New York') & (avocado_data['type'] == 'organic')]['1/total_volume'],\n",
    "            color='green', label='New York - Organic')\n",
    "plt.title('New York / Los Angeles: Inverse Volume vs Price')\n",
    "plt.xlabel('Average Price ($)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae88adb-a444-4b56-a596-d6da96fb48d0",
   "metadata": {},
   "source": [
    "Erkenntnis: Die Städte verhalten sich untereinander unterschiedlich. Wie werden in Regionen oder Städt aufteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd866ea-bba1-4ca2-8194-b7c8f68fa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Fiktive Daten: Geografische Koordinaten für Kalifornien und Mexiko (Hauptanbaugebiete)\n",
    "california_coords = (36.7783, -119.4179)  # Kalifornien (Zentrum)\n",
    "mexico_coords = (23.6345, -102.5528)      # Mexiko (Zentrum)\n",
    "\n",
    "# Umwandeln der geografischen Koordinaten der Regionen in DataFrame\n",
    "static_coordinates = [\n",
    "    ('Albany', 42.6526, -73.7562),\n",
    "    ('Atlanta', 33.749, -84.388)\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(static_coordinates, columns=['city', 'latitude', 'longitude'])\n",
    "\n",
    "# Distanz zu Kalifornien und Mexiko berechnen\n",
    "df['dist_to_california'] = df.apply(lambda row: geodesic((row['latitude'], row['longitude']), california_coords).kilometers, axis=1)\n",
    "df['dist_to_mexico'] = df.apply(lambda row: geodesic((row['latitude'], row['longitude']), mexico_coords).kilometers, axis=1)\n",
    "\n",
    "# Demografische Daten hinzufügen (hier nur 2 Werte, weil wir 2 Städte haben)\n",
    "#df['avg_income'] = [55000, 62000]  # Beispiel-Einkommen für jede Region\n",
    "\n",
    "# Klima-Daten hinzufügen (nur 2 Werte)\n",
    "#df['avg_temp'] = [12.5, 18.2]  # Durchschnittstemperatur der Region\n",
    "\n",
    "# Saisonale Merkmale (2 Werte)\n",
    "#df['season'] = ['Winter', 'Sommer']  # Beispiel: Hinzufügen von Jahreszeiten\n",
    "\n",
    "# Wettbewerb (2 Werte): Anzahl der Supermärkte pro 1000 Einwohner\n",
    "#df['supermarket_density'] = [3.5, 2.2]\n",
    "\n",
    "# Vorschau des DataFrames\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e84388-b12f-45f9-a5fb-869d7836cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the quantiles for price/total volume ratio over time for Los Angeles\n",
    "\n",
    "# Step 1: Calculate the price to volume ratio for Los Angeles\n",
    "avocado_data_la = avocado_data[avocado_data['geography'] == 'Los Angeles'].copy()\n",
    "\n",
    "# Step 1: Calculate the correlation between price and 1/total_volume over time (monthly)\n",
    "avocado_data_la['1/total_volume'] = 1 / avocado_data_la['total_volume']\n",
    "\n",
    "# Group by month and calculate the correlation between price and 1/total_volume for each month\n",
    "davocado_data_la_monthly_corr = avocado_data_la.resample('M', on='date').apply(lambda x: x['average_price'].corr(x['1/total_volume']))\n",
    "\n",
    "# Step 2: Plot the correlation over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(davocado_data_la_monthly_corr.index, davocado_data_la_monthly_corr, label='Price vs 1/Total Volume Correlation', color='purple')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Correlation Between Price and 1/Total Volume Over Time (Los Angeles)', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Correlation Coefficient', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d2bd7-1ae0-4f88-af53-42f8dd3c4294",
   "metadata": {},
   "source": [
    "Erkenntis: Bis auf einige Ausreißer ist eine hohe Korrellation zwischen Preis und 1/Total Volume zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b01cbf-c956-4825-905e-957f7d493654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "# Defining the function to classify regions into West Coast and East Coast\n",
    "def classify_region(geography):\n",
    "    west_coast_regions = ['California', 'Portland', 'Seattle', 'Los Angeles', 'San Francisco']\n",
    "    east_coast_regions = ['New York', 'Boston', 'Miami', 'Philadelphia', 'Baltimore/Washington',\n",
    "                          'Atlanta', 'Tampa', 'Orlando', 'Hartford/Springfield', 'Raleigh/Greensboro', 'Richmond/Norfolk']\n",
    "    \n",
    "    if geography in west_coast_regions:\n",
    "        return 'West Coast'\n",
    "    elif geography in east_coast_regions:\n",
    "        return 'East Coast'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Applying the classification function to create the new region columns\n",
    "avocado_data['coast'] = avocado_data['geography'].apply(classify_region)\n",
    "\n",
    "# Creating binary columns for easier analysis\n",
    "avocado_data['is_west_coast'] = avocado_data['coast'] == 'West Coast'\n",
    "avocado_data['is_east_coast'] = avocado_data['coast'] == 'East Coast'\n",
    "\n",
    "# Displaying the updated dataframe to the user\n",
    "avocado_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39350e-98cf-4508-ba07-837b8b082e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between price and 1/total_volume for East Coast and West Coast regions\n",
    "# Adding 1/total_volume column\n",
    "avocado_data['1/total_volume'] = 1 / avocado_data['total_volume']\n",
    "\n",
    "# Step 1: Calculate correlation for East Coast and West Coast regions\n",
    "\n",
    "# East Coast Correlation for 1/total_volume\n",
    "df_east_coast = avocado_data[avocado_data['is_east_coast']].copy()\n",
    "df_east_coast_corr_inv = df_east_coast.resample('M', on='date').apply(lambda x: x['average_price'].corr(x['1/total_volume']))\n",
    "\n",
    "# West Coast Correlation for 1/total_volume\n",
    "df_west_coast = avocado_data[avocado_data['is_west_coast']].copy()\n",
    "df_west_coast_corr_inv = df_west_coast.resample('M', on='date').apply(lambda x: x['average_price'].corr(x['1/total_volume']))\n",
    "\n",
    "# Step 2: Plotting the correlation over time for both regions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# East Coast plot (price vs 1/total volume)\n",
    "plt.plot(df_east_coast_corr_inv.index, df_east_coast_corr_inv, label='East Coast: Price vs 1/Total Volume', color='blue')\n",
    "\n",
    "# West Coast plot (price vs 1/total volume)\n",
    "plt.plot(df_west_coast_corr_inv.index, df_west_coast_corr_inv, label='West Coast: Price vs 1/Total Volume', color='green')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Correlation Between Price and 1/Total Volume Over Time (East Coast vs West Coast)', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Correlation Coefficient', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195e92f-d36d-408d-96eb-8d266151a87a",
   "metadata": {},
   "source": [
    "Erkenntnis: Die Korrellation Ost und West laufen auseinander."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26ede5-926d-475f-8f36-00ca80abab30",
   "metadata": {},
   "source": [
    "# Schnelle Überprüfung LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b4ce6-ea07-4b9d-9cdd-d8b50f155bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nehmen wir das Jahr 2020 zum trainiren\n",
    "# Anwendung der Klasse auf avocado_data\n",
    "splitter = TimeBasedTrainTestSplit(year_column='year', test_year=2019)\n",
    "\n",
    "# Beispielannahme: y ist der 'average_price', den du vorhersagen möchtest\n",
    "X = avocado_data.drop(columns=['average_price'])  # Merkmale außer average_price\n",
    "y = avocado_data['average_price']  # Zielvariable: average_price\n",
    "\n",
    "# Train-Test-Split anwenden\n",
    "X_train, X_test, y_train, y_test = splitter.transform(X, y)\n",
    "\n",
    "# Ergebnisse überprüfen\n",
    "print(f\"Trainingsdaten: {X_train.shape}, Testdaten: {X_test.shape}\")\n",
    "print(f\"Zielvariable Trainingsdaten: {y_train.shape}, Zielvariable Testdaten: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398505ae-0817-4c03-b83f-52fe680fe32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Zielvariable und Merkmale trennen\n",
    "X = avocado_data.drop(columns=['average_price', 'date'])  # Merkmale\n",
    "y = avocado_data['average_price']  # Zielvariable\n",
    "\n",
    "# Train-Test-Split mit dem TimeBasedTrainTestSplit\n",
    "splitter = TimeBasedTrainTestSplit(year_column='year', test_year=2020)\n",
    "X_train, X_test, y_train, y_test = splitter.transform(X, y)\n",
    "\n",
    "# Definieren der numerischen und kategorischen Spalten\n",
    "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = ['geography']\n",
    "\n",
    "# Erstellen eines Preprocessing-Schritts\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), numerical_features),  # Fehlende numerische Werte mit Median füllen\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=True), categorical_features)  # One-Hot-Encoding der geografischen Spalte\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Erstellen der Pipeline mit Vorverarbeitung und Modell (z.B. Lineare Regression)\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Vorverarbeitungsschritte\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # Skalierung ohne Zentrierung (sparse matrices)\n",
    "    ('model', LinearRegression())  # Modellschritt (z.B. Lineare Regression)\n",
    "])\n",
    "\n",
    "# Pipeline auf den Trainingsdaten trainieren\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R²-Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe50cc-283b-45c1-9c35-a1ad94c05eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Zielvariable und Merkmale trennen\n",
    "X = avocado_data.drop(columns=['average_price', 'date'])  # Merkmale\n",
    "y = avocado_data['average_price']  # Zielvariable\n",
    "\n",
    "# Train-Test-Split mit dem TimeBasedTrainTestSplit\n",
    "splitter = TimeBasedTrainTestSplit(year_column='year', test_year=2020)\n",
    "X_train, X_test, y_train, y_test = splitter.transform(X, y)\n",
    "\n",
    "# Definieren der numerischen und kategorischen Spalten\n",
    "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = ['geography']\n",
    "\n",
    "# Erstellen eines Preprocessing-Schritts\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), numerical_features),  # Fehlende numerische Werte mit Median füllen\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=True), categorical_features)  # One-Hot-Encoding der geografischen Spalte\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Erstellen der Pipeline mit Vorverarbeitung und Modell (z.B. Lineare Regression)\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Vorverarbeitungsschritte\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # Skalierung ohne Zentrierung (sparse matrices)\n",
    "    ('model', LinearRegression())  # Modellschritt (z.B. Lineare Regression)\n",
    "])\n",
    "\n",
    "# Definieren der Parameter für GridSearch\n",
    "param_grid = {\n",
    "    'model__fit_intercept': [True, False],  # Achsenabschnitt einbeziehen oder nicht\n",
    "    'model__n_jobs': [None, -1]  # Anzahl der Jobs für paralleles Berechnen (None=1 Job, -1=alle Kerne)\n",
    "}\n",
    "\n",
    "# GridSearchCV aufsetzen\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')  # R²-Score verwenden\n",
    "\n",
    "# Grid Search auf den Trainingsdaten anwenden\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Beste Parameter und Modell anzeigen\n",
    "print(\"Beste Parameterkombination:\", grid_search.best_params_)\n",
    "\n",
    "# Vorhersage auf den Testdaten mit dem besten Modell\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R²-Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e20bca-6d5f-49ea-b750-c646b35b1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nehmen wir an, dass `date` in den ursprünglichen Daten enthalten war. Du kannst sie wieder zu `X_train` und `X_test` hinzufügen\n",
    "X_test_with_date = X_test.copy()\n",
    "X_test_with_date['date'] = avocado_data.loc[X_test.index, 'date']\n",
    "\n",
    "# Erstellen eines DataFrames für die tatsächlichen und vorhergesagten Werte mit den Testdaten\n",
    "results = pd.DataFrame({\n",
    "    'date': pd.to_datetime(X_test_with_date['date']),\n",
    "    'y_real': y_test,\n",
    "    'y_pred': y_pred\n",
    "})\n",
    "\n",
    "# Sortiere die Ergebnisse nach Datum\n",
    "results = results.sort_values(by='date')\n",
    "\n",
    "# Scatterplot erstellen\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.scatter(results['date'], results['y_real'], label='Tatsächlicher Preis (y_real)', color='blue', alpha=0.6)\n",
    "plt.scatter(results['date'], results['y_pred'], label='Vorhergesagter Preis (y_pred)', color='red', alpha=0.6)\n",
    "plt.title('Tatsächlicher vs. vorhergesagter Preis im Zeitverlauf (Scatterplot)')\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Durchschnittlicher Preis')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ac69f-46eb-4c03-86be-92c40202f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrick Johns\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# Annahme: X_test_with_date enthält die geografischen Daten und 'date'\n",
    "X_test_with_date['date'] = pd.to_datetime(X_test_with_date['date'])\n",
    "\n",
    "# Erstelle einen DataFrame, der sowohl die tatsächlichen als auch die vorhergesagten Werte enthält\n",
    "results = pd.DataFrame({\n",
    "    'date': X_test_with_date['date'],\n",
    "    'geography': X_test_with_date['geography'],\n",
    "    'y_real': y_test,\n",
    "    'y_pred': y_pred\n",
    "})\n",
    "\n",
    "# Liste der verfügbaren geografischen Regionen\n",
    "available_geographies = results['geography'].unique()\n",
    "\n",
    "# Definieren einer Standard-Geografie (\"Los Angeles\")\n",
    "default_geography = 'Los Angeles'\n",
    "\n",
    "# Erstellen der Dash-App\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Layout der App\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Avocado Preis Vorhersage nach Geografie\"),\n",
    "\n",
    "    # Checkbox für die Auswahl von Geografien (nebeneinander)\n",
    "    dcc.Checklist(\n",
    "        id='geography-selector',\n",
    "        options=[{'label': geography, 'value': geography} for geography in available_geographies],\n",
    "        value=[default_geography],  # Standardmäßig ist 'Total U.S.' ausgewählt\n",
    "        labelStyle={'display': 'inline-block', 'margin-right': '10px'}  # Inline und mit Abstand\n",
    "    ),\n",
    "    \n",
    "    # Zeitreihen-Plot\n",
    "    dcc.Graph(id='price-time-series')\n",
    "])\n",
    "\n",
    "# Callback zur Aktualisierung des Plots basierend auf den ausgewählten Regionen\n",
    "@app.callback(\n",
    "    Output('price-time-series', 'figure'),\n",
    "    [Input('geography-selector', 'value')]\n",
    ")\n",
    "def update_time_series(selected_geographies):\n",
    "    # Filtere die Daten nach den ausgewählten Geografien\n",
    "    filtered_data = results[results['geography'].isin(selected_geographies)]\n",
    "    \n",
    "    # Gruppiere die Daten nach Datum und berechne den Durchschnittspreis und die Vorhersage für jede Region\n",
    "    grouped_data = filtered_data.groupby('date').agg({\n",
    "        'y_real': 'mean',\n",
    "        'y_pred': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Erstellen des Plots\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Tatsächlicher Preis\n",
    "    fig.add_trace(go.Scatter(x=grouped_data['date'], y=grouped_data['y_real'],\n",
    "                             mode='lines', name='Tatsächlicher Preis (y_real)', line=dict(color='blue')))\n",
    "\n",
    "    # Vorhergesagter Preis\n",
    "    fig.add_trace(go.Scatter(x=grouped_data['date'], y=grouped_data['y_pred'],\n",
    "                             mode='lines', name='Vorhergesagter Preis (y_pred)', line=dict(color='red', dash='dash')))\n",
    "\n",
    "    # Layout anpassen\n",
    "    fig.update_layout(\n",
    "        title='Tatsächlicher vs. vorhergesagter Preis im Zeitverlauf',\n",
    "        xaxis_title='Datum',\n",
    "        yaxis_title='Durchschnittlicher Preis',\n",
    "        xaxis=dict(type='date'),\n",
    "        height=600\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Starte die Dash-App\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe297552-db2d-4661-9ae4-8d2f3515e80b",
   "metadata": {},
   "source": [
    "Erkenntnis: Teilweise laufen die Schätzungen den tatsächlichen Werten nach. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
